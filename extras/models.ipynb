{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71889df3-4496-4f5d-9ce3-80c5798f6b93",
   "metadata": {},
   "source": [
    "**Ioannis Michalainas** (AEM: 10902) and **Maria Charisi** (AEM: 10727)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d9df0-378e-4b91-a252-04eb7d44a34b",
   "metadata": {},
   "source": [
    "# PART D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00950010-17de-4a14-b610-1b9342ab1d18",
   "metadata": {},
   "source": [
    "First, we begin by importing the necessary libriries. We use **pandas** for loading the datasets and **numpy** for numeric operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be78dd54-772d-454d-9538-4d87e1795411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a98533-dcbd-4905-ab11-67bdfa4266a1",
   "metadata": {},
   "source": [
    "We use **scikit-learn** to test different classifiers on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a54bda-0dba-4593-9422-6ab827d758ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier#, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85b8e23-8ab6-41c0-a98f-cce36e42da4c",
   "metadata": {},
   "source": [
    "After that, we declare some *constants* that will be helpful later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b4de2e-03af-46d9-beb0-c82f413ddb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 224\n",
    "TRAIN_DATA = '../datasets/datasetTV.csv'\n",
    "TEST_DATA = '../datasets/datasetTest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e66316-d14b-4859-8dd2-a624a1ab9404",
   "metadata": {},
   "source": [
    "Finally, we load the **train** and **test** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54c9fd36-6f61-4c91-bf7a-de750d057df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_DATA, header=None)\n",
    "test = pd.read_csv(TEST_DATA, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fb659a-cb4a-49b2-b228-7f9e8eea2889",
   "metadata": {},
   "source": [
    "We *preprocess* the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b185345c-d274-4957-82c0-e139dbbf6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [f'feature_{i+1}' for i in range(NUM_FEATURES)]\n",
    "\n",
    "train.columns = feature_columns + ['label']\n",
    "test.columns = feature_columns  # no 'label' column in the test set\n",
    "\n",
    "# split train data into features and labels\n",
    "X_train = train[feature_columns]\n",
    "y_train = train['label']\n",
    "\n",
    "# test data does not have labels\n",
    "X_test = test[feature_columns]\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8bceed-1056-4437-9f6c-b56ce38e70aa",
   "metadata": {},
   "source": [
    "...and define the **models** we want to test, along with their *parameters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d360893a-4d29-470e-b276-d9590f3d5f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \n",
    "    \"KNN(5NN)\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "\n",
    "    # \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    # \"QDA\": QuadraticDiscriminantAnalysis(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=300, random_state=42),\n",
    "    \"Perceptron\": Perceptron(max_iter=300, random_state=42), # two class problems\n",
    "    \"Least Squares\": RidgeClassifier(),\n",
    "    # \"SGD Classifier\": SGDClassifier(max_iter=1000, tol=1e-3, random_state=42),\n",
    "    \n",
    "    \"SVM\": SVC(kernel='linear', random_state=42),\n",
    "    \n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42),\n",
    "\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \n",
    "    # \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89280810-c599-408d-8a2a-2c79310ee485",
   "metadata": {},
   "source": [
    "We then train each **model** and calculate its accuracy using **5-fold cross-validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c464b4-9ea2-4a82-aaee-8e568f30916a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN(5NN) - Cross-validation accuracy: 0.82\n",
      "KNN(5NN) - Prediction done\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "labelsX_dict = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    results[name] = scores.mean()\n",
    "    print(f\"{name} - Cross-validation accuracy: {scores.mean():.2f}\")\n",
    "\n",
    "    # train model on the entire training set\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    # predict on test data\n",
    "    labelsX = model.predict(X_test_scaled)\n",
    "    # save the predicted labels\n",
    "    labelsX_dict[name] = labelsX\n",
    "    \n",
    "    print(f\"{name} - Prediction done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e976e7f-2373-41e8-ae90-0c61a4e04625",
   "metadata": {},
   "source": [
    "At last, we extract the **predicted labels** in .npy form of the model that scored the best in terms of *accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8830d97c-69cb-4783-bb6c-e1a3f4178efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions from the best model (KNN(5NN)) saved to 'labelsX.npy'\n"
     ]
    }
   ],
   "source": [
    "best_model_name = max(results, key=results.get)\n",
    "best_labelsX = labelsX_dict[best_model_name]\n",
    "np.save('results/labelsX.npy', best_labelsX)\n",
    "\n",
    "print(f\"\\nPredictions from the best model ({best_model_name}) saved to 'labelsX.npy'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
